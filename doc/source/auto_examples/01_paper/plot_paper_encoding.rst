

.. _sphx_glr_auto_examples_01_paper_plot_paper_encoding.py:



.. _pap3:

=========================================
 Encoding
=========================================

Encode text from Rubin et al. (2017) into images.



Start with the necessary imports
--------------------------------



.. code-block:: python

    from os.path import join

    from nilearn import plotting

    from gclda.model import Model
    from gclda.decode import encode
    from gclda.utils import get_resource_path





.. rst-class:: sphx-glr-script-out

 Out::

    Bootstrapped meta-analyses are enabled.


Load model
----------------------------------



.. code-block:: python

    model_file = join(get_resource_path(), 'models/model_Neurosynth2015Filtered2_temp.pklz')
    model = Model.load(model_file)
    model.display_model_summary()





.. rst-class:: sphx-glr-script-out

 Out::

    --- Model Summary ---
     Current State:
             Current Iteration   = 3000
             Initialization Seed = 1
             Current Log-Likely  = -11272693.1084
     Model Hyper-Parameters:
             Symmetric = True
             n_topics  = 200
             n_regions = 2
             alpha     = 0.100
             beta      = 0.010
             gamma     = 0.010
             delta     = 1.000
             roi_size  = 50.000
             dobs      = 25
     Model Training-Data Information:
             Dataset Label                 = Neurosynth2015Filtered2
             Word-Tokens (n_word_tokens)   = 520492
             Peak-Tokens (n_peak_tokens)   = 400801
             Word-Types (n_word_labels)    = 6755
             Documents (n_docs)            = 11362
             Peak-Dimensions (n_peak_dims) = 3


First text
----------------------



.. code-block:: python

    text = 'motor'
    text_img, _ = encode(model, text)
    fig = plotting.plot_stat_map(text_img, display_mode='z',
                                 threshold=0.00001,
                                 cut_coords=[-18, 4, 32, 60])




.. image:: /auto_examples/01_paper/images/sphx_glr_plot_paper_encoding_001.png
    :align: center




Second text
---------------------



.. code-block:: python

    text = 'effort difficult demands'
    text_img, _ = encode(model, text)
    fig = plotting.plot_stat_map(text_img, display_mode='z',
                                 threshold=0.00001,
                                 cut_coords=[-30, -4, 26, 50])




.. image:: /auto_examples/01_paper/images/sphx_glr_plot_paper_encoding_002.png
    :align: center




Third text
------------------



.. code-block:: python

    text = 'painful stimulation during a language task'
    text_img, _ = encode(model, text)
    fig = plotting.plot_stat_map(text_img, display_mode='z',
                                 threshold=0.00001,
                                 cut_coords=[-2, 22, 44, 66])



.. image:: /auto_examples/01_paper/images/sphx_glr_plot_paper_encoding_003.png
    :align: center




**Total running time of the script:** ( 1 minutes  1.219 seconds)



.. only :: html

 .. container:: sphx-glr-footer


  .. container:: sphx-glr-download

     :download:`Download Python source code: plot_paper_encoding.py <plot_paper_encoding.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: plot_paper_encoding.ipynb <plot_paper_encoding.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.readthedocs.io>`_
